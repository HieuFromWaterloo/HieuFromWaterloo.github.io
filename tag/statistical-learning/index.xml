<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Statistical Learning | HIEU QUOC NGUYEN</title>
    <link>https://HieuFromWaterloo.github.io/tag/statistical-learning/</link>
      <atom:link href="https://HieuFromWaterloo.github.io/tag/statistical-learning/index.xml" rel="self" type="application/rss+xml" />
    <description>Statistical Learning</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Thu, 21 Jan 2021 13:00:00 +0000</lastBuildDate>
    <image>
      <url>https://HieuFromWaterloo.github.io/images/icon_hua36de68d39ce8783373fe07433c3394d_363359_512x512_fill_lanczos_center_2.png</url>
      <title>Statistical Learning</title>
      <link>https://HieuFromWaterloo.github.io/tag/statistical-learning/</link>
    </image>
    
    <item>
      <title>Training Latent Dirichlet Allocation with Variational E-M Algorithm</title>
      <link>https://HieuFromWaterloo.github.io/talk/training-latent-dirichlet-allocation-with-variational-e-m-algorithm/</link>
      <pubDate>Thu, 21 Jan 2021 13:00:00 +0000</pubDate>
      <guid>https://HieuFromWaterloo.github.io/talk/training-latent-dirichlet-allocation-with-variational-e-m-algorithm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Deriving Variational E-M Algorithms on Latent Dirichlet Allocation (LDA)</title>
      <link>https://HieuFromWaterloo.github.io/post/lda/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://HieuFromWaterloo.github.io/post/lda/</guid>
      <description>&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;LDA is one of the most important topic models in practice. On a high level, it provides a generative model
that describes how the documents in a dataset are generated; i.e. how words are sampled from multiple
topics to construct a document. This generative process follows a bag of words (BOW) assumption. Hence,
the order in which the word occurs is not taken into account. The core of topic modeling is to analyze unlabeled text data, discover the unknown number of topics and topic distribution in a unsupervised way. This is achieved by making use of statistical inference.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;This note is written based primarily on the following sources:&lt;/p&gt;
&lt;ol start=&#34;0&#34;&gt;
&lt;li&gt;
&lt;p&gt;D. Blei, Andrew Ng, Jordan M. Latent Dirichlet Allocation. Journal of Machine Learning Research. 2003.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reed C. Latent Dirichlet Allocation: Towards a Deeper Understanding. 2012.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Coursera: Bayesian Methods in Machine Learning. National Research University - Higher School of Economics. 2020.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Chenouri S. Stat440/840: Computational Inference. University of Waterloo. 2019.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Lysy M. Stat946: Advanced Computational Inference. University of Waterloo. 2019.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Struthers C. Stat450/850: Estimation and Hypothesis Testing. University of Waterloo. 2018.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bishop C. Pattern Recognition and Machine Learning. Information Science and Statistics. 2006.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Wolf W. Deriving Expectation-Maximization. Blog. 2018.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Serrano L. Latent Dirichlet Distribution. Youtube. 2020.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Predict the Success of Bank Telemarketing</title>
      <link>https://HieuFromWaterloo.github.io/post/stat441/</link>
      <pubDate>Sat, 30 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://HieuFromWaterloo.github.io/post/stat441/</guid>
      <description>&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;The financial sector is in the midst of a transformation. The Canadian industry, long dominated by &amp;ldquo;the Big Five&amp;rdquo; (RBC, CIBC, BMO, TD, and Scotia), is facing increasing competition with international banks and novel technologies such as robo-advisors. This shift is compounded by socioeconomic phenomenon including the foreboding of a North American recession and the global resurgence of populism. Hence, more than ever, financial institutions must identify ways to recruit and retain a loyal customer base. Targeted phone-based campaigns have long been useful tools to this end. In this project, we aim to discover the attributes of a successful telephone-based marketing campaign promoting financial services. In particular, we are interested in identifying the characteristics of clients who have subscribed to a term deposit with a bank after being contacted by a customer engagement representative. We will be utilizing campaign led by a Portuguese bank between 2008 and 2010 to fit a variety of classification models.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Detect Potential Financing Deals in Capital Markets</title>
      <link>https://HieuFromWaterloo.github.io/post/gib/</link>
      <pubDate>Fri, 30 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://HieuFromWaterloo.github.io/post/gib/</guid>
      <description>&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;In this project, as far as data science concerns, we have 3 main goals. First, we need to apply Machine Learning to effectively analyze, forecast and detect anomalies in stock trends in Canadian financial markets. Second, we need to deploy Natural Language Processing methodologies on financial news and earning calls to successfully pick up the key indicators that lead to a capital intensive activities (mergers and acquisitions, strategic expansion, debt maturities due, etc.). Lastly, we need to incorporate the output from the previous two objectives along with other relevant factors and train an algorithm to detect potential capital funding opportunities in an unsupervised fashion.&lt;/p&gt;
&lt;p&gt;Note: due to confidential reasons, materials for this project is reserved&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Property Evaluation</title>
      <link>https://HieuFromWaterloo.github.io/post/stat444/</link>
      <pubDate>Sat, 13 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://HieuFromWaterloo.github.io/post/stat444/</guid>
      <description>&lt;p&gt;Provided the Washing D.C residential data set, our objective is to build statistical learning algorithms to predict the housing prices in the capital of the United States. In this project, we design 4 different models, all being trained and validated based on the Root Mean Squared Log Error (RMSLE) over 5-fold cross validation. The first model is smoothing, which has the error (RMLSE) of 0.19856. The second model is random forest, which produces the error (RMLSE) of 0.180. Third, our boosting model has an error of 0.16746. Lastly, we took the average of the predictions from random forest and boosting and get an error of 0.17162&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An Introduction to Graph Convolution Networks (GCN)</title>
      <link>https://HieuFromWaterloo.github.io/talk/an-introduction-to-graph-convolution-networks-gcn/</link>
      <pubDate>Thu, 06 Dec 2018 13:00:00 +0000</pubDate>
      <guid>https://HieuFromWaterloo.github.io/talk/an-introduction-to-graph-convolution-networks-gcn/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
